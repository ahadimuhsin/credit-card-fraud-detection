{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('F:\\Kuliah\\Semester 7\\Data Mining\\Data Dow Jones\\creditcard.csv', sep=',')\n",
    "#data diambil dari kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "data2 = data\n",
    "\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "5            2.0  -0.425966   0.960523  1.141109 -0.168252  0.420987   \n",
      "6            4.0   1.229658   0.141004  0.045371  1.202613  0.191881   \n",
      "7            7.0  -0.644269   1.417964  1.074380 -0.492199  0.948934   \n",
      "8            7.0  -0.894286   0.286157 -0.113192 -0.271526  2.669599   \n",
      "9            9.0  -0.338262   1.119593  1.044367 -0.222187  0.499361   \n",
      "10          10.0   1.449044  -1.176339  0.913860 -1.375667 -1.971383   \n",
      "11          10.0   0.384978   0.616109 -0.874300 -0.094019  2.924584   \n",
      "12          10.0   1.249999  -1.221637  0.383930 -1.234899 -1.485419   \n",
      "13          11.0   1.069374   0.287722  0.828613  2.712520 -0.178398   \n",
      "14          12.0  -2.791855  -0.327771  1.641750  1.767473 -0.136588   \n",
      "15          12.0  -0.752417   0.345485  2.057323 -1.468643 -1.158394   \n",
      "16          12.0   1.103215  -0.040296  1.267332  1.289091 -0.735997   \n",
      "17          13.0  -0.436905   0.918966  0.924591 -0.727219  0.915679   \n",
      "18          14.0  -5.401258  -5.450148  1.186305  1.736239  3.049106   \n",
      "19          15.0   1.492936  -1.029346  0.454795 -1.438026 -1.555434   \n",
      "20          16.0   0.694885  -1.361819  1.029221  0.834159 -1.191209   \n",
      "21          17.0   0.962496   0.328461 -0.171479  2.109204  1.129566   \n",
      "22          18.0   1.166616   0.502120 -0.067300  2.261569  0.428804   \n",
      "23          18.0   0.247491   0.277666  1.185471 -0.092603 -1.314394   \n",
      "24          22.0  -1.946525  -0.044901 -0.405570 -1.013057  2.941968   \n",
      "25          22.0  -2.074295  -0.121482  1.322021  0.410008  0.295198   \n",
      "26          23.0   1.173285   0.353498  0.283905  1.133563 -0.172577   \n",
      "27          23.0   1.322707  -0.174041  0.434555  0.576038 -0.836758   \n",
      "28          23.0  -0.414289   0.905437  1.727453  1.473471  0.007443   \n",
      "29          23.0   1.059387  -0.175319  1.266130  1.186110 -0.786002   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284777  172764.0   2.079137  -0.028723 -1.343392  0.358000 -0.045791   \n",
      "284778  172764.0  -0.764523   0.588379 -0.907599 -0.418847  0.901528   \n",
      "284779  172766.0   1.975178  -0.616244 -2.628295 -0.406246  2.327804   \n",
      "284780  172766.0  -1.727503   1.108356  2.219561  1.148583 -0.884199   \n",
      "284781  172766.0  -1.139015  -0.155510  1.894478 -1.138957  1.451777   \n",
      "284782  172767.0  -0.268061   2.540315 -1.400915  4.846661  0.639105   \n",
      "284783  172768.0  -1.796092   1.929178 -2.828417 -1.689844  2.199572   \n",
      "284784  172768.0  -0.669662   0.923769 -1.543167 -1.560729  2.833960   \n",
      "284785  172768.0   0.032887   0.545338 -1.185844 -1.729828  2.932315   \n",
      "284786  172768.0  -2.076175   2.142238 -2.522704 -1.888063  1.982785   \n",
      "284787  172769.0  -1.029719  -1.110670 -0.636179 -0.840816  2.424360   \n",
      "284788  172770.0   2.007418  -0.280235 -0.208113  0.335261 -0.715798   \n",
      "284789  172770.0  -0.446951   1.302212 -0.168583  0.981577  0.578957   \n",
      "284790  172771.0  -0.515513   0.971950 -1.014580 -0.677037  0.912430   \n",
      "284791  172774.0  -0.863506   0.874701  0.420358 -0.530365  0.356561   \n",
      "284792  172774.0  -0.724123   1.485216 -1.132218 -0.607190  0.709499   \n",
      "284793  172775.0   1.971002  -0.699067 -1.697541 -0.617643  1.718797   \n",
      "284794  172777.0  -1.266580  -0.400461  0.956221 -0.723919  1.531993   \n",
      "284795  172778.0 -12.516732  10.187818 -8.476671 -2.510473 -4.586669   \n",
      "284796  172780.0   1.884849  -0.143540 -0.999943  1.506772 -0.035300   \n",
      "284797  172782.0  -0.241923   0.712247  0.399806 -0.463406  0.244531   \n",
      "284798  172782.0   0.219529   0.881246 -0.635891  0.960928 -0.152971   \n",
      "284799  172783.0  -1.775135  -0.004235  1.189786  0.331096  1.196063   \n",
      "284800  172784.0   2.039560  -0.175233 -1.196825  0.234580 -0.008713   \n",
      "284801  172785.0   0.120316   0.931005 -0.546012 -0.745097  1.130314   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...         V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ...   -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ...   -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...    0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ...   -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ...   -0.009431  0.798278   \n",
      "5      -0.029728  0.476201  0.260314 -0.568671  ...   -0.208254 -0.559825   \n",
      "6       0.272708 -0.005159  0.081213  0.464960  ...   -0.167716 -0.270710   \n",
      "7       0.428118  1.120631 -3.807864  0.615375  ...    1.943465 -1.015455   \n",
      "8       3.721818  0.370145  0.851084 -0.392048  ...   -0.073425 -0.268092   \n",
      "9      -0.246761  0.651583  0.069539 -0.736727  ...   -0.246914 -0.633753   \n",
      "10     -0.629152 -1.423236  0.048456 -1.720408  ...   -0.009302  0.313894   \n",
      "11      3.317027  0.470455  0.538247 -0.558895  ...    0.049924  0.238422   \n",
      "12     -0.753230 -0.689405 -0.227487 -2.094011  ...   -0.231809 -0.483285   \n",
      "13      0.337544 -0.096717  0.115982 -0.221083  ...   -0.036876  0.074412   \n",
      "14      0.807596 -0.422911 -1.907107  0.755713  ...    1.151663  0.222182   \n",
      "15     -0.077850 -0.608581  0.003603 -0.436167  ...    0.499625  1.353650   \n",
      "16      0.288069 -0.586057  0.189380  0.782333  ...   -0.024612  0.196002   \n",
      "17     -0.127867  0.707642  0.087962 -0.665271  ...   -0.194796 -0.672638   \n",
      "18     -1.763406 -1.559738  0.160842  1.233090  ...   -0.503600  0.984460   \n",
      "19     -0.720961 -1.080664 -0.053127 -1.978682  ...   -0.177650 -0.175074   \n",
      "20      1.309109 -0.878586  0.445290 -0.446196  ...   -0.295583 -0.571955   \n",
      "21      1.696038  0.107712  0.521502 -1.191311  ...    0.143997  0.402492   \n",
      "22      0.089474  0.241147  0.138082 -0.989162  ...    0.018702 -0.061972   \n",
      "23     -0.150116 -0.946365 -1.617935  1.544071  ...    1.650180  0.200454   \n",
      "24      2.955053 -0.063063  0.855546  0.049967  ...   -0.579526 -0.799229   \n",
      "25     -0.959537  0.543985 -0.104627  0.475664  ...   -0.403639 -0.227404   \n",
      "26     -0.916054  0.369025 -0.327260 -0.246651  ...    0.067003  0.227812   \n",
      "27     -0.831083 -0.264905 -0.220982 -1.071425  ...   -0.284376 -0.323357   \n",
      "28     -0.200331  0.740228 -0.029247 -0.593392  ...    0.077237  0.457331   \n",
      "29      0.578435 -0.767084  0.401046  0.699500  ...    0.013676  0.213734   \n",
      "...          ...       ...       ...       ...  ...         ...       ...   \n",
      "284777 -1.345452  0.227476 -0.378355  0.665911  ...    0.235758  0.829758   \n",
      "284778 -0.760802  0.758545  0.414698 -0.730854  ...    0.003530 -0.431876   \n",
      "284779  3.664740 -0.533297  0.842937  1.128798  ...    0.086043  0.543613   \n",
      "284780  0.793083 -0.527298  0.866429  0.853819  ...   -0.094708  0.236818   \n",
      "284781  0.093598  0.191353  0.092211 -0.062621  ...   -0.191027 -0.631658   \n",
      "284782  0.186479 -0.045911  0.936448 -2.419986  ...   -0.263889 -0.857904   \n",
      "284783  3.123732 -0.270714  1.657495  0.465804  ...    0.271170  1.145750   \n",
      "284784  3.240843  0.181576  1.282746 -0.893890  ...    0.183856  0.202670   \n",
      "284785  3.401529  0.337434  0.925377 -0.165663  ...   -0.266113 -0.716336   \n",
      "284786  3.732950 -1.217430 -0.536644  0.272867  ...    2.016666 -1.588269   \n",
      "284787 -2.956733  0.283610 -0.332656 -0.247488  ...    0.353722  0.488487   \n",
      "284788 -0.751373 -0.458972 -0.140140  0.959971  ...   -0.208260 -0.430347   \n",
      "284789 -0.605641  1.253430 -1.042610 -0.417116  ...    0.851800  0.305268   \n",
      "284790 -0.316187  0.396137  0.532364 -0.224606  ...   -0.280302 -0.849919   \n",
      "284791 -1.046238  0.757051  0.230473 -0.506856  ...   -0.108846 -0.480820   \n",
      "284792 -0.482638  0.548393  0.343003 -0.226323  ...    0.414621  1.307511   \n",
      "284793  3.911336 -1.259306  1.056209  1.315006  ...    0.188758  0.694418   \n",
      "284794 -1.788600  0.314741  0.004704  0.013857  ...   -0.157831 -0.883365   \n",
      "284795 -1.394465 -3.632516  5.498583  4.893089  ...   -0.944759 -1.565026   \n",
      "284796 -0.613638  0.190241 -0.249058  0.666458  ...    0.144008  0.634646   \n",
      "284797 -1.343668  0.929369 -0.206210  0.106234  ...   -0.228876 -0.514376   \n",
      "284798 -1.014307  0.427126  0.121340 -0.285670  ...    0.099936  0.337120   \n",
      "284799  5.519980 -1.518185  2.080825  1.159498  ...    0.103302  0.654850   \n",
      "284800 -0.726571  0.017050 -0.118228  0.435402  ...   -0.268048 -0.717211   \n",
      "284801 -0.235973  0.812722  0.115093 -0.204064  ...   -0.314205 -0.808520   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...    0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...    0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...    0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...    0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...    0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "5      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
      "6      -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99   \n",
      "7       0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   40.80   \n",
      "8      -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   93.20   \n",
      "9      -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68   \n",
      "10      0.027740  0.500512  0.251367 -0.129478  0.042850  0.016253    7.80   \n",
      "11      0.009130  0.996710 -0.767315 -0.492208  0.042472 -0.054337    9.99   \n",
      "12      0.084668  0.392831  0.161135 -0.354990  0.026416  0.042422  121.50   \n",
      "13     -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   27.50   \n",
      "14      1.020586  0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80   \n",
      "15     -0.256573 -0.065084 -0.039124 -0.087086 -0.180998  0.129394   15.99   \n",
      "16      0.013802  0.103758  0.364298 -0.382261  0.092809  0.037051   12.99   \n",
      "17     -0.156858 -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89   \n",
      "18      2.458589  0.042119 -0.481631 -0.621272  0.392053  0.949594   46.80   \n",
      "19      0.040002  0.295814  0.332931 -0.220385  0.022298  0.007602    5.00   \n",
      "20     -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.71   \n",
      "21     -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   34.09   \n",
      "22     -0.103855 -0.370415  0.603200  0.108556 -0.040521 -0.011418    2.28   \n",
      "23     -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75   \n",
      "24      0.870300  0.983421  0.321201  0.149650  0.707519  0.014600    0.89   \n",
      "25      0.742435  0.398535  0.249212  0.274404  0.359969  0.243232   26.43   \n",
      "26     -0.150487  0.435045  0.724825 -0.337082  0.016368  0.030041   41.88   \n",
      "27     -0.037710  0.347151  0.559639 -0.280158  0.042335  0.028822   16.00   \n",
      "28     -0.038500  0.642522 -0.183891 -0.277464  0.182687  0.152665   33.00   \n",
      "29      0.014462  0.002951  0.294638 -0.395070  0.081461  0.024220   12.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284777 -0.002063  0.001344  0.262183 -0.105327 -0.022363 -0.060283    1.00   \n",
      "284778  0.141759  0.587119 -0.200998  0.267337 -0.152951 -0.065285   80.00   \n",
      "284779 -0.032129  0.768379  0.477688 -0.031833  0.014151 -0.066542   25.00   \n",
      "284780 -0.204280  1.158185  0.627801 -0.399981  0.510818  0.233265   30.00   \n",
      "284781 -0.147249  0.212931  0.354257 -0.241068 -0.161717 -0.149188   13.00   \n",
      "284782  0.235172 -0.681794 -0.668894  0.044657 -0.066751 -0.072447   12.82   \n",
      "284783  0.084783  0.721269 -0.529906 -0.240117  0.129126 -0.080620   11.46   \n",
      "284784 -0.373023  0.651122  1.073823  0.844590 -0.286676 -0.187719   40.00   \n",
      "284785  0.108519  0.688519 -0.460220  0.161939  0.265368  0.090245    1.79   \n",
      "284786  0.588482  0.632444 -0.201064  0.199251  0.438657  0.172923    8.95   \n",
      "284787  0.293632  0.107812 -0.935586  1.138216  0.025271  0.255347    9.99   \n",
      "284788  0.416765  0.064819 -0.608337  0.268436 -0.028069 -0.041367    3.99   \n",
      "284789 -0.148093 -0.038712  0.010209 -0.362666  0.503092  0.229921   60.50   \n",
      "284790  0.300245  0.000607 -0.376379  0.128660 -0.015205 -0.021486    9.81   \n",
      "284791 -0.074513 -0.003988 -0.113149  0.280378 -0.077310  0.023079   20.32   \n",
      "284792 -0.059545  0.242669 -0.665424 -0.269869 -0.170579 -0.030692    3.99   \n",
      "284793  0.163002  0.726365 -0.058282 -0.191813  0.061858 -0.043716    4.99   \n",
      "284794  0.088485 -0.076790 -0.095833  0.132720 -0.028468  0.126494    0.89   \n",
      "284795  0.890675 -1.253276  1.786717  0.320763  2.090712  1.232864    9.87   \n",
      "284796 -0.042114 -0.053206  0.316403 -0.461441  0.018265 -0.041068   60.00   \n",
      "284797  0.279598  0.371441 -0.559238  0.113144  0.131507  0.081265    5.49   \n",
      "284798  0.251791  0.057688 -1.508368  0.144023  0.181205  0.215243   24.05   \n",
      "284799 -0.348929  0.745323  0.704545 -0.127579  0.454379  0.130308   79.99   \n",
      "284800  0.297930 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68   \n",
      "284801  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          0  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          0  \n",
      "19          0  \n",
      "20          0  \n",
      "21          0  \n",
      "22          0  \n",
      "23          0  \n",
      "24          0  \n",
      "25          0  \n",
      "26          0  \n",
      "27          0  \n",
      "28          0  \n",
      "29          0  \n",
      "...       ...  \n",
      "284777      0  \n",
      "284778      0  \n",
      "284779      0  \n",
      "284780      0  \n",
      "284781      0  \n",
      "284782      0  \n",
      "284783      0  \n",
      "284784      0  \n",
      "284785      0  \n",
      "284786      0  \n",
      "284787      0  \n",
      "284788      0  \n",
      "284789      0  \n",
      "284790      0  \n",
      "284791      0  \n",
      "284792      0  \n",
      "284793      0  \n",
      "284794      0  \n",
      "284795      0  \n",
      "284796      0  \n",
      "284797      0  \n",
      "284798      0  \n",
      "284799      0  \n",
      "284800      0  \n",
      "284801      0  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "##memeriksa persentase data transaksi yang termasuk non fraud dan fraud pada dataset\n",
    "print('No Frauds', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##melakukan feature scaling\n",
    "##Feature Scaling adalah suatu cara untuk membuat numerical data \n",
    "##pada dataset memiliki rentang nilai (scale) yang sama. \n",
    "##Tidak ada lagi satu variabel data yang mendominasi variabel data lainnya.\n",
    "\n",
    "##membuat sub-sample dengan data 50/50\n",
    "##men-scale kolom Time dan Amount, karena kolom yang lain sudah di-scale\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler menghilangkan median dan men-scale data berdasarkan quartile range-nya\n",
    "# StandardScaler menghilangkan mean dan men-scale data ke unit variance\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "#data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount        V1        V2        V3        V4        V5        V6  \\\n",
       "0       1.783274 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1      -0.269825  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       4.983721 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1.418291 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       0.670579 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...         V20       V21       V22  \\\n",
       "0  0.239599  0.098698  0.363787  ...    0.251412 -0.018307  0.277838   \n",
       "1 -0.078803  0.085102 -0.255425  ...   -0.069083 -0.225775 -0.638672   \n",
       "2  0.791461  0.247676 -1.514654  ...    0.524980  0.247998  0.771679   \n",
       "3  0.237609  0.377436 -1.387024  ...   -0.208038 -0.108300  0.005274   \n",
       "4  0.592941 -0.270533  0.817739  ...    0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mengubah nama kolom Time Amount menjadi scaled_time dan scaled_amount\n",
    "scaled_amount = data['scaled_amount']\n",
    "#scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "#data.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n",
      "Train: [265518 180305  42664 ...  29062  13766  17677] Test: [263020  11378 147283 ... 274532 269819  64170]\n",
      "Train: [ 72227 114282  16818 ... 264471 191914 284017] Test: [202638  32978 128121 ... 244024 127667  48318]\n",
      "Train: [ 20895 114622 167683 ... 244502 178972 218506] Test: [284352  82483  90981 ... 171224 168807 271602]\n",
      "Train: [122248 181660 194400 ... 104631 277586  29432] Test: [225673  63348  68025 ... 279451  77554  76043]\n",
      "Train: [241684 223467 136928 ...  86495 160550  49633] Test: [157557 204860  83760 ... 251478 178967 216850]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827075 0.00172925]\n",
      "[0.99827955 0.00172045]\n"
     ]
    }
   ],
   "source": [
    "##Splitting Data dari Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "print('No Frauds', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset')\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
    "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "original_Xtrain.shape\n",
    "\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222842</th>\n",
       "      <td>0.181513</td>\n",
       "      <td>1.963033</td>\n",
       "      <td>-0.324752</td>\n",
       "      <td>-0.560659</td>\n",
       "      <td>0.293549</td>\n",
       "      <td>-0.254647</td>\n",
       "      <td>-0.126789</td>\n",
       "      <td>-0.411838</td>\n",
       "      <td>-0.036800</td>\n",
       "      <td>1.139476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069007</td>\n",
       "      <td>-0.178320</td>\n",
       "      <td>-0.414064</td>\n",
       "      <td>0.334408</td>\n",
       "      <td>0.454989</td>\n",
       "      <td>-0.346183</td>\n",
       "      <td>-0.645499</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>-0.019816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>4.313523</td>\n",
       "      <td>-6.891438</td>\n",
       "      <td>6.796797</td>\n",
       "      <td>0.616297</td>\n",
       "      <td>-2.966327</td>\n",
       "      <td>-2.436653</td>\n",
       "      <td>0.489328</td>\n",
       "      <td>-3.371639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632710</td>\n",
       "      <td>0.536892</td>\n",
       "      <td>-0.546126</td>\n",
       "      <td>-0.605240</td>\n",
       "      <td>-0.263743</td>\n",
       "      <td>1.539916</td>\n",
       "      <td>0.523574</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.572741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275256</th>\n",
       "      <td>-0.100468</td>\n",
       "      <td>-1.151910</td>\n",
       "      <td>-0.399565</td>\n",
       "      <td>-0.674712</td>\n",
       "      <td>-2.257572</td>\n",
       "      <td>4.062472</td>\n",
       "      <td>2.778476</td>\n",
       "      <td>0.132998</td>\n",
       "      <td>0.951063</td>\n",
       "      <td>-0.294986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041540</td>\n",
       "      <td>-0.105252</td>\n",
       "      <td>-0.700066</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.694377</td>\n",
       "      <td>0.029512</td>\n",
       "      <td>0.093576</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.130929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42696</th>\n",
       "      <td>0.925452</td>\n",
       "      <td>-8.426814</td>\n",
       "      <td>6.241659</td>\n",
       "      <td>-9.946470</td>\n",
       "      <td>8.199614</td>\n",
       "      <td>-8.213093</td>\n",
       "      <td>-2.522046</td>\n",
       "      <td>-11.643028</td>\n",
       "      <td>5.339500</td>\n",
       "      <td>-7.051016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563869</td>\n",
       "      <td>2.427460</td>\n",
       "      <td>0.692667</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>0.483162</td>\n",
       "      <td>1.195671</td>\n",
       "      <td>0.198294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41569</th>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-2.377533</td>\n",
       "      <td>0.520539</td>\n",
       "      <td>-8.094139</td>\n",
       "      <td>8.005351</td>\n",
       "      <td>2.640750</td>\n",
       "      <td>-3.381586</td>\n",
       "      <td>-1.934372</td>\n",
       "      <td>0.562322</td>\n",
       "      <td>-3.104027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634747</td>\n",
       "      <td>0.148284</td>\n",
       "      <td>0.721100</td>\n",
       "      <td>2.661291</td>\n",
       "      <td>-0.508620</td>\n",
       "      <td>-0.401657</td>\n",
       "      <td>0.587611</td>\n",
       "      <td>0.500326</td>\n",
       "      <td>0.551760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount        V1        V2        V3        V4        V5  \\\n",
       "222842       0.181513  1.963033 -0.324752 -0.560659  0.293549 -0.254647   \n",
       "6719        -0.293440 -0.251471  4.313523 -6.891438  6.796797  0.616297   \n",
       "275256      -0.100468 -1.151910 -0.399565 -0.674712 -2.257572  4.062472   \n",
       "42696        0.925452 -8.426814  6.241659 -9.946470  8.199614 -8.213093   \n",
       "41569       -0.293440 -2.377533  0.520539 -8.094139  8.005351  2.640750   \n",
       "\n",
       "              V6         V7        V8        V9  ...         V20       V21  \\\n",
       "222842 -0.126789  -0.411838 -0.036800  1.139476  ...   -0.069007 -0.178320   \n",
       "6719   -2.966327  -2.436653  0.489328 -3.371639  ...    0.632710  0.536892   \n",
       "275256  2.778476   0.132998  0.951063 -0.294986  ...    0.041540 -0.105252   \n",
       "42696  -2.522046 -11.643028  5.339500 -7.051016  ...    0.563869  2.427460   \n",
       "41569  -3.381586  -1.934372  0.562322 -3.104027  ...   -0.634747  0.148284   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "222842 -0.414064  0.334408  0.454989 -0.346183 -0.645499  0.030838 -0.019816   \n",
       "6719   -0.546126 -0.605240 -0.263743  1.539916  0.523574  0.891025  0.572741   \n",
       "275256 -0.700066  0.061678  0.694377  0.029512  0.093576  0.005254  0.130929   \n",
       "42696   0.692667  0.020305  0.499809  0.467594  0.483162  1.195671  0.198294   \n",
       "41569   0.721100  2.661291 -0.508620 -0.401657  0.587611  0.500326  0.551760   \n",
       "\n",
       "        Class  \n",
       "222842      0  \n",
       "6719        1  \n",
       "275256      0  \n",
       "42696       1  \n",
       "41569       1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Membuat sub sample 50:50\n",
    "\n",
    "#Karena ada 492 kasus transaksi fraud, maka akan diambil secara acak 492 kasus transaksi non-fraud\n",
    "\n",
    "#merandom dataset\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "#mengambil seluruh data fraud dan 492 kasus data non-fraud\n",
    "fraud_data = data.loc[data['Class'] == 1]\n",
    "nonFraud_data = data.loc[data['Class']==0][:492]\n",
    "\n",
    "#menggabungkan data fraud dan non-fraud\n",
    "normal_distributed_data = pd.concat([fraud_data, nonFraud_data])\n",
    "\n",
    "#membuat dataframe baru yang berisi sub sample 50:50 kemudian mengacak baris pada data baru\n",
    "subSample_data = normal_distributed_data.sample(frac=1, random_state=42)\n",
    "# subSample_data.shape\n",
    "subSample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling sebelum melakukan cross-validation\n",
    "\n",
    "X = subSample_data.drop('Class', axis=1)\n",
    "y = subSample_data['Class']\n",
    "\n",
    "#Memecah dataframe baru menjadi training dan test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "#test_size = perbandingan pembagian training test dengan testing set\n",
    "#total data = 984\n",
    "#training set = 787\n",
    "#testing set = 197\n",
    "\n",
    "#mengubah ke array agar lebih mudah untuk algoritma klasifikasi\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# X_train.shape\n",
    "# X_test.shape\n",
    "#y_train.shape\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression training skor akurasinya 94.0 %\n",
      "Training logistic regression untuk sub sample 50:50 memakan waktu: 0.128088 detik\n"
     ]
    }
   ],
   "source": [
    "#Menerapkan algoritma klasifikasi Logistic Regression\n",
    "\n",
    "classifiers = {\"LogReg\" : LogisticRegression()}\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "t0 = time.time()\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train,\n",
    "                                    cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"training skor akurasinya\", round(training_score.mean(),2)*100,\n",
    "         \"%\")\n",
    "t1 = time.time()\n",
    "\n",
    "print ('Training logistic regression untuk sub sample 50:50 memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# t0 = time.time()\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "# We automatically get the logistic regression with the best parameters.\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "# log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "# print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "# t1 = time.time()\n",
    "# print ('Cross Validation pada Logistic Regression untuk sub sample 50:50 memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.9806347359575982\n",
      "Menghitung skor AUC Logistic Regression untuk sub sample 50:50 memakan waktu: 0.245165 detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Create a DataFrame with all the scores and the classifiers names.\n",
    "t0 = time.time()\n",
    "log_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5,\n",
    "                             method=\"decision_function\")\n",
    "print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\n",
    "t1 = time.time()\n",
    "\n",
    "print ('Menghitung skor AUC Logistic Regression untuk sub sample 50:50 memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Logistic Regression:\n",
      "Recall Score: 0.94\n",
      "Precision Score: 0.98\n",
      "F1 Score: 0.96\n",
      "Accuracy Score: 0.96\n",
      "Menghitung recall, precision, f1, dan akurasi pada Logistic Regression untuk sub sample 50:50 memerlukan waktu: 0.022012 detik\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "t0= time.time()\n",
    "y_pred = log_reg.predict(X_train)\n",
    "\n",
    "print ('Classification Report Logistic Regression:')\n",
    "print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))\n",
    "print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))\n",
    "print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "\n",
    "t1= time.time()\n",
    "print ('Menghitung recall, precision, f1, dan akurasi pada Logistic Regression untuk sub sample 50:50 memerlukan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mengambil seluruh data fraud dan non-fraud\n",
    "fraud_data_all = data2.loc[data2['Class'] == 1]\n",
    "nonFraud_data_all = data2.loc[data2['Class']==0]\n",
    "\n",
    "#menggabungkan data fraud dan non-fraud\n",
    "normal_distributed_data_all = pd.concat([fraud_data_all, nonFraud_data_all])\n",
    "normal_distributed_data_all.shape\n",
    "#normal_distributed_data_all.head()\n",
    "# data2.head()\n",
    "#fraud_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = normal_distributed_data_all.drop('Class', axis=1)\n",
    "y2 = normal_distributed_data_all['Class']\n",
    "\n",
    "#Memecah dataframe baru menjadi training dan test set\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size=0.2, random_state=42)\n",
    "\n",
    "#mengubah ke array agar lebih mudah untuk algoritma klasifikasi\n",
    "X_train2 = X_train2.values\n",
    "X_test2 = X_test2.values\n",
    "y_train2 = y_train2.values\n",
    "y_test2 = y_test2.values\n",
    "\n",
    "#y_train2.shape\n",
    "#y_test2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression training skor akurasinya 100.0 %\n",
      "Training logistic regression untuk seluruh data memakan waktu: 61.562849 detik\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train2, y_train2)\n",
    "    training_score = cross_val_score(classifier, X_train2, y_train2,\n",
    "                                    cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"training skor akurasinya\", round(training_score.mean(),2)*100,\n",
    "         \"%\")\n",
    "t1 = time.time()\n",
    "\n",
    "print ('Training logistic regression untuk seluruh data memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg2 = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg2.fit(X_train2, y_train2)\n",
    "# We automatically get the logistic regression with the best parameters.\n",
    "log_reg2 = grid_log_reg2.best_estimator_\n",
    "\n",
    "# log_reg_score2 = cross_val_score(log_reg2, X_train2, y_train2, cv=5)\n",
    "# print('Logistic Regression Cross Validation Score: ', round(log_reg_score2.mean() * 100, 2).astype(str) + '%')\n",
    "# t1 = time.time()\n",
    "# print ('Cross Validation pada Logistic Regression untuk seluruh data memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.960492719624437\n",
      "Menghitung skor AUC Logistic Regression untuk seluruh data memakan waktu: 24.446222 detik\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "log_reg_pred2 = cross_val_predict(log_reg2, X_train2, y_train2, cv=5,\n",
    "                             method=\"decision_function\")\n",
    "print('Logistic Regression: ', roc_auc_score(y_train2, log_reg_pred2))\n",
    "t1 = time.time()\n",
    "\n",
    "print ('Menghitung skor AUC Logistic Regression untuk seluruh data memakan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Logistic Regression:\n",
      "Recall Score: 0.60\n",
      "Precision Score: 0.87\n",
      "F1 Score: 0.71\n",
      "Accuracy Score: 1.00\n",
      "Menghitung recall, precision, f1, dan akurasi pada Logistic Regression untuk seluruh data memerlukan waktu: 0.509337 detik\n"
     ]
    }
   ],
   "source": [
    "t0= time.time()\n",
    "y_pred2 = log_reg2.predict(X_train2)\n",
    "\n",
    "print ('Classification Report Logistic Regression:')\n",
    "print('Recall Score: {:.2f}'.format(recall_score(y_train2, y_pred2)))\n",
    "print('Precision Score: {:.2f}'.format(precision_score(y_train2, y_pred2)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_train2, y_pred2)))\n",
    "print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train2, y_pred2)))\n",
    "\n",
    "t1= time.time()\n",
    "print ('Menghitung recall, precision, f1, dan akurasi pada Logistic Regression untuk seluruh data memerlukan waktu: {:3f} detik' .format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Menerapkan confusion matrix pada testing set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "log_reg_cf = confusion_matrix(y_test, y_pred_log_reg)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "#classNames = ['Positive', 'Negative']\n",
    "sns.heatmap(log_reg_cf, annot=True, cmap=plt.cm.inferno)\n",
    "plt.title(\"Confusion Matrix dengan Logistic Regression \\n Pada Data Down Sampling\", fontsize=14)\n",
    "#tick_marks = np.arrange(len(classNames))\n",
    "plt.xlabel('Predicted', fontsize=19)\n",
    "plt.ylabel('Actual', fontsize=19)\n",
    "\n",
    "# s = [['TN','FP'], ['FN', 'TP']]\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         plt.text(j,i, str(s[i][j])+\" = \"+str(log_reg_cf[i][j]))\n",
    "\n",
    "#TN = kiri atas -->Non Fraud\n",
    "#FP = kanan atas\n",
    "#FN = kiri bawah\n",
    "#TP = kanan bawah -->Fraud\n",
    "\n",
    "ax.set_xticklabels(['Negative', 'Positive'], fontsize=14, rotation=360)\n",
    "ax.set_yticklabels(['Negative', 'Positive'], fontsize=14, rotation=360)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_log_reg2 = log_reg2.predict(X_test2)\n",
    "\n",
    "log_reg_cf2 = confusion_matrix(y_test2, y_pred_log_reg2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "#classNames = ['Positive', 'Negative']\n",
    "sns.heatmap(log_reg_cf2, annot=True, cmap=plt.cm.inferno)\n",
    "plt.title(\"Confusion Matrix dengan Logistic Regression \\n Pada Seluruh Data\", fontsize=14)\n",
    "#tick_marks = np.arrange(len(classNames))\n",
    "plt.xlabel('Predicted', fontsize=19)\n",
    "plt.ylabel('Actual', fontsize=19)\n",
    "\n",
    "#TN = kiri atas -->Non Fraud\n",
    "#FP = kanan atas\n",
    "#FN = kiri bawah\n",
    "#TP = kanan bawah -->Fraud\n",
    "\n",
    "ax.set_xticklabels(['Negative', 'Positive'], fontsize=14, rotation=360)\n",
    "ax.set_yticklabels(['Negative', 'Positive'], fontsize=14, rotation=360)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression dengan Down Sampling:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        87\n",
      "          1       1.00      0.91      0.95       110\n",
      "\n",
      "avg / total       0.95      0.95      0.95       197\n",
      "\n",
      "Logistic Regression dengan Seluruh Data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56866\n",
      "          1       0.88      0.51      0.64        96\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Laporan Hasil Klasifikasi\n",
    "\n",
    "print('Logistic Regression dengan Down Sampling:')\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "\n",
    "print('Logistic Regression dengan Seluruh Data:')\n",
    "print(classification_report(y_test2, y_pred_log_reg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
