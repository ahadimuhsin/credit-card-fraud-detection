{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step), \n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('F:\\Kuliah\\Semester 7\\Data Mining\\Data Dow Jones\\creditcard.csv', sep=',')\n",
    "#data diambil dari kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean   94813.859575      0.000000      0.000000     -0.000000      0.000000   \n",
       "std    47488.145955      1.958696      1.651309      1.516255      1.415869   \n",
       "min        0.000000    -56.407510    -72.715728    -48.325589     -5.683171   \n",
       "25%    54201.500000     -0.920373     -0.598550     -0.890365     -0.848640   \n",
       "50%    84692.000000      0.018109      0.065486      0.179846     -0.019847   \n",
       "75%   139320.500000      1.315642      0.803724      1.027196      0.743341   \n",
       "max   172792.000000      2.454930     22.057729      9.382558     16.875344   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean      -0.000000      0.000000     -0.000000     -0.000000     -0.000000   \n",
       "std        1.380247      1.332271      1.237094      1.194353      1.098632   \n",
       "min     -113.743307    -26.160506    -43.557242    -73.216718    -13.434066   \n",
       "25%       -0.691597     -0.768296     -0.554076     -0.208630     -0.643098   \n",
       "50%       -0.054336     -0.274187      0.040103      0.022358     -0.051429   \n",
       "75%        0.611926      0.398565      0.570436      0.327346      0.597139   \n",
       "max       34.801666     73.301626    120.589494     20.007208     15.594995   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ... 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean   ...      0.000000      0.000000      0.000000      0.000000   \n",
       "std    ...      0.734524      0.725702      0.624460      0.605647   \n",
       "min    ...    -34.830382    -10.933144    -44.807735     -2.836627   \n",
       "25%    ...     -0.228395     -0.542350     -0.161846     -0.354586   \n",
       "50%    ...     -0.029450      0.006782     -0.011193      0.040976   \n",
       "75%    ...      0.186377      0.528554      0.147642      0.439527   \n",
       "max    ...     27.202839     10.503090     22.528412      4.584549   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count 284807.000000 284807.000000 284807.000000 284807.000000 284807.000000   \n",
       "mean       0.000000      0.000000     -0.000000     -0.000000     88.349619   \n",
       "std        0.521278      0.482227      0.403632      0.330083    250.120109   \n",
       "min      -10.295397     -2.604551    -22.565679    -15.430084      0.000000   \n",
       "25%       -0.317145     -0.326984     -0.070840     -0.052960      5.600000   \n",
       "50%        0.016594     -0.052139      0.001342      0.011244     22.000000   \n",
       "75%        0.350716      0.240952      0.091045      0.078280     77.165000   \n",
       "max        7.519589      3.517346     31.612198     33.847808  25691.160000   \n",
       "\n",
       "              Class  \n",
       "count 284807.000000  \n",
       "mean       0.001727  \n",
       "std        0.041527  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print rangkuman statistik per feature\n",
    "pd.options.display.float_format = \"{:.6f}\".format\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('No Frauds', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot('Class', data=data, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount        V1        V2       V3        V4        V5        V6  \\\n",
       "0       0.244964 -1.359807 -0.072781 2.536347  1.378155 -0.338321  0.462388   \n",
       "1      -0.342475  1.191857  0.266151 0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1.160686 -1.358354 -1.340163 1.773209  0.379780 -0.503198  1.800499   \n",
       "3       0.140534 -0.966272 -0.185226 1.792993 -0.863291 -0.010309  1.247203   \n",
       "4      -0.073403 -1.158233  0.877737 1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler menghilangkan median dan men-scale data berdasarkan quartile range-nya\n",
    "# StandardScaler menghilangkan mean dan men-scale data ke unit variance\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "data['scaled_amount'] = std_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "#data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "#mengubah nama kolom Time Amount menjadi scaled_time dan scaled_amount\n",
    "scaled_amount = data['scaled_amount']\n",
    "#scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "#data.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rincian class pada data training Counter({0: 227449, 1: 396}) dan testing Counter({0: 56866, 1: 96}) \n"
     ]
    }
   ],
   "source": [
    "fraud_data_all = data.loc[data['Class'] == 1]\n",
    "nonFraud_data_all = data.loc[data['Class']==0]\n",
    "\n",
    "#menggabungkan data fraud dan non-fraud\n",
    "normal_distributed_data_all = pd.concat([fraud_data_all, nonFraud_data_all])\n",
    "normal_distributed_data_all.shape\n",
    "#normal_distributed_data_all.head()\n",
    "# data2.head()\n",
    "#fraud_data_all.shape\n",
    "\n",
    "X = normal_distributed_data_all.drop('Class', axis=1)\n",
    "y = normal_distributed_data_all['Class']\n",
    "#X2 --> variabel label untuk prediksi\n",
    "#y2 --> variabel feature, semua kolom kecuali X (Class)\n",
    "#Memecah dataframe baru menjadi training dan test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "print (\"Rincian class pada data training {} dan testing {} \" .format(Counter(y_train), Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma=1.5, kernel='rbf', C=1)\n",
    "svm.fit(X_train,y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227449      0]\n",
      " [    21    375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227449\n",
      "           1       1.00      0.95      0.97       396\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    227845\n",
      "   macro avg       1.00      0.97      0.99    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "0.9731236802019038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = svm.predict(X_train)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_pred)\n",
    "print (conf_matrix_train)\n",
    "# print (X.shape)\n",
    "print (classification_report(y_train, y_pred))\n",
    "G_mean = geometric_mean_score(y_train, y_pred)\n",
    "print (G_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56866     0]\n",
      " [   94     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56866\n",
      "           1       1.00      0.02      0.04        96\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     56962\n",
      "   macro avg       1.00      0.51      0.52     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "0.14433756729740643\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = svm.predict(X_test)\n",
    "# print(X_test.shape)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "print (conf_matrix_test)\n",
    "# print (X_test.dtype)\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "G_mean_test = geometric_mean_score (y_test, y_pred_test)\n",
    "print (G_mean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
